# =============================================================================
# Telco Workshop - Local Deployment Configuration
# =============================================================================
# All services run locally in Docker: ClickHouse, Langfuse, LibreChat, MCP, etc.
#
# Setup:
#   make setup-local   (copies this file to .env and generates security keys)
#
# For detailed setup instructions, see the README.md Setup Guide section.
# =============================================================================

DEPLOY_MODE=local

# -----------------------------------------------------------------------------
# ClickHouse Configuration (local Docker)
# -----------------------------------------------------------------------------
# ClickHouse 25.8+ requires a password for the default user.
CLICKHOUSE_HOST=clickhouse
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=clickhouse
CLICKHOUSE_SECURE=false
CLICKHOUSE_VERIFY=false

# -----------------------------------------------------------------------------
# Langfuse Configuration (local Docker)
# -----------------------------------------------------------------------------
# Langfuse is the open-source LLMOps platform used for tracing and observability.

# PostgreSQL backend for Langfuse (internal, no need to change)
LANGFUSE_DB_USER=langfuse
LANGFUSE_DB_PASSWORD=langfuse
LANGFUSE_DB_NAME=langfuse

# Langfuse application settings
LANGFUSE_URL=http://localhost:3000

# Generate secure random values for these two fields:
#   openssl rand -hex 32
LANGFUSE_SECRET=<generate-with-openssl-rand-hex-32>
LANGFUSE_SALT=<generate-with-openssl-rand-hex-32>

# Set to false to disable anonymous telemetry
LANGFUSE_TELEMETRY=false

# Langfuse headless initialization (auto-creates org, user, project, and API keys)
# These values are used by both Langfuse (to initialize) and LibreChat (to trace).
LANGFUSE_INIT_ORG_ID=telco-workshop
LANGFUSE_INIT_ORG_NAME=Telco Workshop
LANGFUSE_INIT_PROJECT_ID=telco-analytics
LANGFUSE_INIT_PROJECT_NAME=Telco Analytics
LANGFUSE_INIT_USER_EMAIL=admin@telco.local
LANGFUSE_INIT_USER_NAME=Admin
LANGFUSE_INIT_USER_PASSWORD=admin123

# API keys for Langfuse project (auto-generated by make setup-local).
# These are passed to BOTH the Langfuse container (LANGFUSE_INIT_PROJECT_PUBLIC_KEY)
# and LibreChat (LANGFUSE_PUBLIC_KEY) to connect tracing automatically.
LANGFUSE_INIT_PROJECT_PUBLIC_KEY=<generate-langfuse-pk>
LANGFUSE_INIT_PROJECT_SECRET_KEY=<generate-langfuse-sk>

# LibreChat reads these to connect to Langfuse (must match the INIT keys above)
LANGFUSE_PUBLIC_KEY=<generate-langfuse-pk>
LANGFUSE_SECRET_KEY=<generate-langfuse-sk>
LANGFUSE_BASE_URL=http://langfuse:3000

# -----------------------------------------------------------------------------
# LibreChat Configuration
# -----------------------------------------------------------------------------
ENDPOINTS=agents
PORT=3080
CREDS_KEY=<generate-with-openssl-rand-hex-32>
CREDS_IV=<generate-with-openssl-rand-hex-16>
JWT_SECRET=<generate-with-openssl-rand-hex-32>
JWT_REFRESH_SECRET=<generate-with-openssl-rand-hex-32>
MEILI_MASTER_KEY=<generate-with-openssl-rand-hex-16>
MEILI_HOST=http://meilisearch:7700
MONGO_URI=mongodb://mongodb:27017/LibreChat
DOMAIN_CLIENT=http://localhost:3080
DOMAIN_SERVER=http://localhost:3080

# Default workshop user (auto-created by `make start`)
LIBRECHAT_USER_EMAIL=admin@telco.local
LIBRECHAT_USER_NAME=Admin
LIBRECHAT_USER_PASSWORD=workshop123

# -----------------------------------------------------------------------------
# LiteLLM Proxy Configuration
# -----------------------------------------------------------------------------
# LiteLLM routes all LLM calls through a proxy for Langfuse tracing.
# Models are configured in litellm_config.yaml (not here).
LITELLM_MASTER_KEY=<generate-with-openssl-rand-hex-32>

# LLM_ENDPOINT and LLM_MODEL are no longer used. Models are defined in
# litellm_config.yaml and the librechat yaml template. Kept here for reference:
# LLM_ENDPOINT=google
# LLM_MODEL=gemini-2.0-flash

# -----------------------------------------------------------------------------
# LLM Provider API Keys
# -----------------------------------------------------------------------------
# Set the API key for the provider matching LLM_ENDPOINT above.
# Leave others as user_provided (or remove them).

# Google AI (Gemini API direct -- uses API key, not Vertex AI)
GOOGLE_KEY=user_provided

# Anthropic (direct API)
ANTHROPIC_API_KEY=user_provided

# OpenAI (direct API)
OPENAI_API_KEY=user_provided

# -----------------------------------------------------------------------------
# Vertex AI Configuration (optional, replaces direct API keys above)
# -----------------------------------------------------------------------------
# To use Google Vertex AI instead of direct API keys:
#   1. Create a GCP service account with "Vertex AI User" role
#   2. Download the JSON key file and place it in this directory as auth.json
#   3. Comment out GOOGLE_KEY above (they conflict)
#   4. Uncomment the lines below
#
# GOOGLE_SERVICE_KEY_FILE=/app/api/data/auth.json
# GOOGLE_LOC=us-central1
#
# For Anthropic Claude models via Vertex AI, see the librechat.yaml vertex
# section in the LibreChat docs: https://www.librechat.ai/docs/configuration

# -----------------------------------------------------------------------------
# ClickHouse MCP Server
# -----------------------------------------------------------------------------
CLICKHOUSE_MCP_SERVER_TRANSPORT=sse
CLICKHOUSE_MCP_BIND_HOST=0.0.0.0

# -----------------------------------------------------------------------------
# Data Generator Configuration
# -----------------------------------------------------------------------------
# These control the volume and composition of generated data.
#
# DATA_SIZE: T-shirt size preset that overrides individual variables below.
# When set, NUM_CUSTOMERS, NUM_DAYS, NUM_CAMPAIGNS, and EVENTS_PER_DAY are
# ignored. Leave empty (or comment out) to use individual variables.
#
# Available presets:
# +---------+------------+------+-----------+------------+-----------+-----------------+
# | Size    | Customers  | Days | Campaigns | Events/Day | ~CDRs     | ~Network Events |
# +---------+------------+------+-----------+------------+-----------+-----------------+
# | small   | 1,000      | 7    | 10        | 500        | 70,000    | 3,500           |
# | medium  | 10,000     | 30   | 100       | 10,000     | 3,000,000 | 300,000         |
# | large   | 50,000     | 60   | 500       | 25,000     | 30M       | 1,500,000       |
# | 2xl     | 100,000    | 90   | 1,000     | 50,000     | 90M       | 4,500,000       |
# +---------+------------+------+-----------+------------+-----------+-----------------+
#
# DATA_SIZE=medium

# Individual data volume controls (used when DATA_SIZE is not set).
# Default values below correspond to the "medium" preset.
NUM_CUSTOMERS=10000
NUM_DAYS=30
NUM_CAMPAIGNS=100
EVENTS_PER_DAY=10000

# Random seed for reproducible data generation.
# Change this to generate a different (but still reproducible) dataset.
DATA_SEED=42

# Which datasets to generate:
#   all       - customers, CDRs, network_events, campaigns (default)
#   network   - network_events only (for network observability testing)
#   marketing - customers, CDRs, and campaigns (for marketing analytics testing)
GENERATE_DATASETS=all
